{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, max_pad_len=100):\n",
    "    try:\n",
    "        # Load the audio file\n",
    "        audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
    "\n",
    "        # Extract MFCC features from the audio\n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "\n",
    "        # Pad the MFCC array to ensure consistent shape\n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model\n",
    "def create_cnn_model(input_shape, num_classes):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # First convolutional layer\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Second convolutional layer\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Third convolutional layer\n",
    "    model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    \n",
    "    # Flatten the output and add dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "file_path = 'path_to_audio_file.wav'\n",
    "mfccs = extract_features(file_path)\n",
    "mfccs = np.expand_dims(mfccs, axis=-1)  # Add channel dimension\n",
    "\n",
    "# Parameters\n",
    "input_shape = (time_steps, frequency_bins, 1)  # Replace with actual values\n",
    "num_classes = 12  # 10 words + \"is_unknown\" + \"_silence_\"\n",
    "\n",
    "# Create the model\n",
    "model = create_cnn_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=3, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Save the model\n",
    "model.save('audio_classification_cnn.h5')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
